2025-02-02 15:12:56,459 - DEBUG - Starting application
2025-02-02 15:12:56,557 - DEBUG - Loading stylesheet from resources/dark_mode.qss
2025-02-02 15:12:56,558 - DEBUG - Initializing MainWindow
2025-02-02 15:12:56,561 - DEBUG - uiname is MainWindow
2025-02-02 15:12:56,561 - DEBUG - toplevel widget is MainWindow
2025-02-02 15:12:56,561 - DEBUG - setting property geometry
2025-02-02 15:12:56,561 - DEBUG - setting property windowTitle
2025-02-02 15:12:56,561 - DEBUG - push MainWindow MainWindow
2025-02-02 15:12:56,561 - DEBUG - push QWidget centralwidget
2025-02-02 15:12:56,561 - DEBUG - setting property pyuicMargins
2025-02-02 15:12:56,561 - DEBUG - push QVBoxLayout verticalLayout
2025-02-02 15:12:56,561 - DEBUG - setting property orientation
2025-02-02 15:12:56,562 - DEBUG - push QSplitter splitter
2025-02-02 15:12:56,562 - DEBUG - push QWidget leftPanel
2025-02-02 15:12:56,562 - DEBUG - setting property pyuicMargins
2025-02-02 15:12:56,562 - DEBUG - push QVBoxLayout leftLayout
2025-02-02 15:12:56,562 - DEBUG - setting property text
2025-02-02 15:12:56,562 - DEBUG - push QPushButton uploadButton
2025-02-02 15:12:56,562 - DEBUG - pop widget QPushButton uploadButton
2025-02-02 15:12:56,562 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x126ec2e70>
2025-02-02 15:12:56,563 - DEBUG - push QListWidget documentList
2025-02-02 15:12:56,563 - DEBUG - pop widget QListWidget documentList
2025-02-02 15:12:56,563 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x126ec2e70>
2025-02-02 15:12:56,563 - DEBUG - pop layout QVBoxLayout leftLayout
2025-02-02 15:12:56,563 - DEBUG - pop widget QWidget leftPanel
2025-02-02 15:12:56,563 - DEBUG - new topwidget <PyQt5.QtWidgets.QSplitter object at 0x126ec2d50>
2025-02-02 15:12:56,581 - DEBUG - push QWidget rightPanel
2025-02-02 15:12:56,581 - DEBUG - setting property pyuicMargins
2025-02-02 15:12:56,581 - DEBUG - push QVBoxLayout rightLayout
2025-02-02 15:12:56,582 - DEBUG - setting property widgetResizable
2025-02-02 15:12:56,582 - DEBUG - push QScrollArea chatScrollArea
2025-02-02 15:12:56,582 - DEBUG - push QWidget chatContainer
2025-02-02 15:12:56,582 - DEBUG - setting property alignment
2025-02-02 15:12:56,582 - DEBUG - push QVBoxLayout chatLayout
2025-02-02 15:12:56,582 - DEBUG - pop layout QVBoxLayout chatLayout
2025-02-02 15:12:56,582 - DEBUG - pop widget QWidget chatContainer
2025-02-02 15:12:56,582 - DEBUG - new topwidget <PyQt5.QtWidgets.QScrollArea object at 0x126ec31d0>
2025-02-02 15:12:56,582 - DEBUG - pop widget QScrollArea chatScrollArea
2025-02-02 15:12:56,582 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x126ec3140>
2025-02-02 15:12:56,582 - DEBUG - push QHBoxLayout inputLayout
2025-02-02 15:12:56,582 - DEBUG - setting property placeholderText
2025-02-02 15:12:56,582 - DEBUG - push QLineEdit promptInput
2025-02-02 15:12:56,582 - DEBUG - pop widget QLineEdit promptInput
2025-02-02 15:12:56,582 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x126ec3140>
2025-02-02 15:12:56,582 - DEBUG - setting property text
2025-02-02 15:12:56,582 - DEBUG - push QPushButton sendButton
2025-02-02 15:12:56,582 - DEBUG - pop widget QPushButton sendButton
2025-02-02 15:12:56,582 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x126ec3140>
2025-02-02 15:12:56,582 - DEBUG - pop layout QHBoxLayout inputLayout
2025-02-02 15:12:56,582 - DEBUG - pop layout QVBoxLayout rightLayout
2025-02-02 15:12:56,582 - DEBUG - pop widget QWidget rightPanel
2025-02-02 15:12:56,582 - DEBUG - new topwidget <PyQt5.QtWidgets.QSplitter object at 0x126ec2d50>
2025-02-02 15:12:56,582 - DEBUG - pop widget QSplitter splitter
2025-02-02 15:12:56,582 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x126ec2330>
2025-02-02 15:12:56,582 - DEBUG - pop layout QVBoxLayout verticalLayout
2025-02-02 15:12:56,582 - DEBUG - pop widget QWidget centralwidget
2025-02-02 15:12:56,582 - DEBUG - new topwidget <__main__.MainWindow object at 0x126ec2cc0>
2025-02-02 15:12:56,582 - DEBUG - pop widget MainWindow MainWindow
2025-02-02 15:12:56,582 - DEBUG - new topwidget None
2025-02-02 15:12:56,583 - DEBUG - Loading configuration from config.yaml
2025-02-02 15:12:56,583 - DEBUG - Initializing RAG
2025-02-02 15:12:56,594 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-02 15:12:56,698 - DEBUG - Starting component System
2025-02-02 15:12:56,698 - DEBUG - Starting component Posthog
2025-02-02 15:12:56,698 - DEBUG - Starting component OpenTelemetryClient
2025-02-02 15:12:56,698 - DEBUG - Starting component SqliteDB
2025-02-02 15:12:56,700 - DEBUG - Starting component SimpleQuotaEnforcer
2025-02-02 15:12:56,700 - DEBUG - Starting component SimpleRateLimitEnforcer
2025-02-02 15:12:56,700 - DEBUG - Starting component LocalSegmentManager
2025-02-02 15:12:56,700 - DEBUG - Starting component LocalExecutor
2025-02-02 15:12:56,700 - DEBUG - Starting component SegmentAPI
2025-02-02 15:12:56,702 - DEBUG - Collection doc already exists, returning existing collection.
2025-02-02 15:12:56,786 - INFO - Loading all indices.
2025-02-02 15:12:56,786 - DEBUG - > [SimpleDirectoryReader] Total files added: 1
2025-02-02 15:12:57,042 - DEBUG - open file: /Users/wingatesv/gen_ai/documents/Marketing and Sales - X.pdf
2025-02-02 15:12:57,042 - WARNING - incorrect startxref pointer(1)
2025-02-02 15:12:57,064 - WARNING - parsing for Object Streams
2025-02-02 15:12:57,108 - WARNING - found 0 objects within Object(381,0) whereas 500 expected
2025-02-02 15:12:57,114 - WARNING - found 0 objects within Object(922,0) whereas 500 expected
2025-02-02 15:12:57,119 - WARNING - found 0 objects within Object(1428,0) whereas 500 expected
2025-02-02 15:12:57,124 - WARNING - found 0 objects within Object(1933,0) whereas 500 expected
2025-02-02 15:12:57,129 - WARNING - found 0 objects within Object(2443,0) whereas 500 expected
2025-02-02 15:12:57,134 - WARNING - found 0 objects within Object(2946,0) whereas 500 expected
2025-02-02 15:12:57,140 - WARNING - found 0 objects within Object(3456,0) whereas 500 expected
2025-02-02 15:12:57,145 - WARNING - found 0 objects within Object(3970,0) whereas 500 expected
2025-02-02 15:12:57,157 - WARNING - found 0 objects within Object(4476,0) whereas 337 expected
2025-02-02 15:12:57,214 - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-02-02 15:12:57,539 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,539 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,539 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,539 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,539 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,539 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,539 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,540 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,541 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,542 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,543 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,544 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,545 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,546 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,546 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,546 - DEBUG - > Adding chunk: 
2025-02-02 15:12:57,547 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:12:58,441 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-02 15:12:59,238 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-02 15:12:59,473 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:01,486 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:03,351 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:06,214 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:13,210 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:14,971 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:17,181 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:19,185 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:21,279 - DEBUG - Using selector: KqueueSelector
2025-02-02 15:13:23,420 - DEBUG - Starting component PersistentLocalHnswSegment
2025-02-02 15:13:23,496 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/docstore.json
2025-02-02 15:13:23,496 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/index_store.json
2025-02-02 15:13:23,497 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/graph_store.json
2025-02-02 15:13:23,497 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/image__vector_store.json
2025-02-02 15:13:23,497 - DEBUG - Setting up internal folder: documents
2025-02-02 15:13:23,497 - DEBUG - Updating document list
2025-02-02 15:13:24,258 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-03 13:52:17,967 - DEBUG - Starting application
2025-02-03 13:52:18,096 - DEBUG - Loading stylesheet from resources/dark_mode.qss
2025-02-03 13:52:18,097 - DEBUG - Initializing MainWindow
2025-02-03 13:52:18,104 - DEBUG - uiname is MainWindow
2025-02-03 13:52:18,105 - DEBUG - toplevel widget is MainWindow
2025-02-03 13:52:18,105 - DEBUG - setting property geometry
2025-02-03 13:52:18,105 - DEBUG - setting property windowTitle
2025-02-03 13:52:18,105 - DEBUG - push MainWindow MainWindow
2025-02-03 13:52:18,106 - DEBUG - push QWidget centralwidget
2025-02-03 13:52:18,106 - DEBUG - setting property pyuicMargins
2025-02-03 13:52:18,106 - DEBUG - push QVBoxLayout verticalLayout
2025-02-03 13:52:18,107 - DEBUG - setting property orientation
2025-02-03 13:52:18,108 - DEBUG - push QSplitter splitter
2025-02-03 13:52:18,108 - DEBUG - push QWidget leftPanel
2025-02-03 13:52:18,108 - DEBUG - setting property pyuicMargins
2025-02-03 13:52:18,108 - DEBUG - push QVBoxLayout leftLayout
2025-02-03 13:52:18,109 - DEBUG - setting property text
2025-02-03 13:52:18,110 - DEBUG - push QPushButton uploadButton
2025-02-03 13:52:18,110 - DEBUG - pop widget QPushButton uploadButton
2025-02-03 13:52:18,110 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e71ee70>
2025-02-03 13:52:18,113 - DEBUG - push QListWidget documentList
2025-02-03 13:52:18,113 - DEBUG - pop widget QListWidget documentList
2025-02-03 13:52:18,113 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e71ee70>
2025-02-03 13:52:18,113 - DEBUG - pop layout QVBoxLayout leftLayout
2025-02-03 13:52:18,113 - DEBUG - pop widget QWidget leftPanel
2025-02-03 13:52:18,113 - DEBUG - new topwidget <PyQt5.QtWidgets.QSplitter object at 0x10e71ed50>
2025-02-03 13:52:18,138 - DEBUG - push QWidget rightPanel
2025-02-03 13:52:18,138 - DEBUG - setting property pyuicMargins
2025-02-03 13:52:18,138 - DEBUG - push QVBoxLayout rightLayout
2025-02-03 13:52:18,139 - DEBUG - setting property widgetResizable
2025-02-03 13:52:18,139 - DEBUG - push QScrollArea chatScrollArea
2025-02-03 13:52:18,139 - DEBUG - push QWidget chatContainer
2025-02-03 13:52:18,139 - DEBUG - setting property alignment
2025-02-03 13:52:18,139 - DEBUG - push QVBoxLayout chatLayout
2025-02-03 13:52:18,139 - DEBUG - pop layout QVBoxLayout chatLayout
2025-02-03 13:52:18,139 - DEBUG - pop widget QWidget chatContainer
2025-02-03 13:52:18,139 - DEBUG - new topwidget <PyQt5.QtWidgets.QScrollArea object at 0x10e71f1d0>
2025-02-03 13:52:18,139 - DEBUG - pop widget QScrollArea chatScrollArea
2025-02-03 13:52:18,139 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e71f140>
2025-02-03 13:52:18,139 - DEBUG - push QHBoxLayout inputLayout
2025-02-03 13:52:18,140 - DEBUG - setting property placeholderText
2025-02-03 13:52:18,140 - DEBUG - push QLineEdit promptInput
2025-02-03 13:52:18,140 - DEBUG - pop widget QLineEdit promptInput
2025-02-03 13:52:18,140 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e71f140>
2025-02-03 13:52:18,140 - DEBUG - setting property text
2025-02-03 13:52:18,140 - DEBUG - push QPushButton sendButton
2025-02-03 13:52:18,140 - DEBUG - pop widget QPushButton sendButton
2025-02-03 13:52:18,140 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e71f140>
2025-02-03 13:52:18,140 - DEBUG - pop layout QHBoxLayout inputLayout
2025-02-03 13:52:18,141 - DEBUG - pop layout QVBoxLayout rightLayout
2025-02-03 13:52:18,141 - DEBUG - pop widget QWidget rightPanel
2025-02-03 13:52:18,141 - DEBUG - new topwidget <PyQt5.QtWidgets.QSplitter object at 0x10e71ed50>
2025-02-03 13:52:18,141 - DEBUG - pop widget QSplitter splitter
2025-02-03 13:52:18,141 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e71e330>
2025-02-03 13:52:18,141 - DEBUG - pop layout QVBoxLayout verticalLayout
2025-02-03 13:52:18,141 - DEBUG - pop widget QWidget centralwidget
2025-02-03 13:52:18,141 - DEBUG - new topwidget <__main__.MainWindow object at 0x10e71ecc0>
2025-02-03 13:52:18,141 - DEBUG - pop widget MainWindow MainWindow
2025-02-03 13:52:18,141 - DEBUG - new topwidget None
2025-02-03 13:52:18,141 - DEBUG - Loading configuration from config.yaml
2025-02-03 13:52:18,142 - DEBUG - Initializing RAG
2025-02-03 13:52:18,154 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-03 13:52:18,278 - DEBUG - Starting component System
2025-02-03 13:52:18,278 - DEBUG - Starting component Posthog
2025-02-03 13:52:18,278 - DEBUG - Starting component OpenTelemetryClient
2025-02-03 13:52:18,278 - DEBUG - Starting component SqliteDB
2025-02-03 13:52:18,284 - DEBUG - Starting component SimpleQuotaEnforcer
2025-02-03 13:52:18,284 - DEBUG - Starting component SimpleRateLimitEnforcer
2025-02-03 13:52:18,284 - DEBUG - Starting component LocalSegmentManager
2025-02-03 13:52:18,284 - DEBUG - Starting component LocalExecutor
2025-02-03 13:52:18,284 - DEBUG - Starting component SegmentAPI
2025-02-03 13:52:18,287 - DEBUG - Collection doc already exists, returning existing collection.
2025-02-03 13:52:18,378 - INFO - Loading all indices.
2025-02-03 13:52:18,378 - DEBUG - > [SimpleDirectoryReader] Total files added: 1
2025-02-03 13:52:18,793 - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-02-03 13:52:18,911 - DEBUG - open file: /Users/wingatesv/gen_ai/documents/Marketing and Sales - X.pdf
2025-02-03 13:52:18,912 - WARNING - incorrect startxref pointer(1)
2025-02-03 13:52:18,934 - WARNING - parsing for Object Streams
2025-02-03 13:52:18,978 - WARNING - found 0 objects within Object(381,0) whereas 500 expected
2025-02-03 13:52:18,984 - WARNING - found 0 objects within Object(922,0) whereas 500 expected
2025-02-03 13:52:18,989 - WARNING - found 0 objects within Object(1428,0) whereas 500 expected
2025-02-03 13:52:18,994 - WARNING - found 0 objects within Object(1933,0) whereas 500 expected
2025-02-03 13:52:18,999 - WARNING - found 0 objects within Object(2443,0) whereas 500 expected
2025-02-03 13:52:19,004 - WARNING - found 0 objects within Object(2946,0) whereas 500 expected
2025-02-03 13:52:19,010 - WARNING - found 0 objects within Object(3456,0) whereas 500 expected
2025-02-03 13:52:19,015 - WARNING - found 0 objects within Object(3970,0) whereas 500 expected
2025-02-03 13:52:19,029 - WARNING - found 0 objects within Object(4476,0) whereas 337 expected
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,431 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,432 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,433 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,434 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,435 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,436 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,437 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,437 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,437 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,437 - DEBUG - > Adding chunk: 
2025-02-03 13:52:19,439 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:52:20,076 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-03 13:52:20,894 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-03 13:52:20,944 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:52:22,153 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:52:23,472 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:52:24,755 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:52:26,026 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:52:27,292 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:52:28,578 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:22,834 - DEBUG - Starting application
2025-02-03 13:53:22,923 - DEBUG - Loading stylesheet from resources/dark_mode.qss
2025-02-03 13:53:22,923 - DEBUG - Initializing MainWindow
2025-02-03 13:53:22,924 - DEBUG - uiname is MainWindow
2025-02-03 13:53:22,925 - DEBUG - toplevel widget is MainWindow
2025-02-03 13:53:22,925 - DEBUG - setting property geometry
2025-02-03 13:53:22,925 - DEBUG - setting property windowTitle
2025-02-03 13:53:22,925 - DEBUG - push MainWindow MainWindow
2025-02-03 13:53:22,925 - DEBUG - push QWidget centralwidget
2025-02-03 13:53:22,925 - DEBUG - setting property pyuicMargins
2025-02-03 13:53:22,925 - DEBUG - push QVBoxLayout verticalLayout
2025-02-03 13:53:22,925 - DEBUG - setting property orientation
2025-02-03 13:53:22,926 - DEBUG - push QSplitter splitter
2025-02-03 13:53:22,926 - DEBUG - push QWidget leftPanel
2025-02-03 13:53:22,926 - DEBUG - setting property pyuicMargins
2025-02-03 13:53:22,926 - DEBUG - push QVBoxLayout leftLayout
2025-02-03 13:53:22,926 - DEBUG - setting property text
2025-02-03 13:53:22,926 - DEBUG - push QPushButton uploadButton
2025-02-03 13:53:22,926 - DEBUG - pop widget QPushButton uploadButton
2025-02-03 13:53:22,926 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e026e70>
2025-02-03 13:53:22,927 - DEBUG - push QListWidget documentList
2025-02-03 13:53:22,927 - DEBUG - pop widget QListWidget documentList
2025-02-03 13:53:22,927 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e026e70>
2025-02-03 13:53:22,927 - DEBUG - pop layout QVBoxLayout leftLayout
2025-02-03 13:53:22,927 - DEBUG - pop widget QWidget leftPanel
2025-02-03 13:53:22,927 - DEBUG - new topwidget <PyQt5.QtWidgets.QSplitter object at 0x10e026d50>
2025-02-03 13:53:22,945 - DEBUG - push QWidget rightPanel
2025-02-03 13:53:22,945 - DEBUG - setting property pyuicMargins
2025-02-03 13:53:22,945 - DEBUG - push QVBoxLayout rightLayout
2025-02-03 13:53:22,945 - DEBUG - setting property widgetResizable
2025-02-03 13:53:22,945 - DEBUG - push QScrollArea chatScrollArea
2025-02-03 13:53:22,945 - DEBUG - push QWidget chatContainer
2025-02-03 13:53:22,945 - DEBUG - setting property alignment
2025-02-03 13:53:22,945 - DEBUG - push QVBoxLayout chatLayout
2025-02-03 13:53:22,945 - DEBUG - pop layout QVBoxLayout chatLayout
2025-02-03 13:53:22,945 - DEBUG - pop widget QWidget chatContainer
2025-02-03 13:53:22,945 - DEBUG - new topwidget <PyQt5.QtWidgets.QScrollArea object at 0x10e0271d0>
2025-02-03 13:53:22,945 - DEBUG - pop widget QScrollArea chatScrollArea
2025-02-03 13:53:22,946 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e027140>
2025-02-03 13:53:22,946 - DEBUG - push QHBoxLayout inputLayout
2025-02-03 13:53:22,946 - DEBUG - setting property placeholderText
2025-02-03 13:53:22,946 - DEBUG - push QLineEdit promptInput
2025-02-03 13:53:22,946 - DEBUG - pop widget QLineEdit promptInput
2025-02-03 13:53:22,946 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e027140>
2025-02-03 13:53:22,946 - DEBUG - setting property text
2025-02-03 13:53:22,946 - DEBUG - push QPushButton sendButton
2025-02-03 13:53:22,946 - DEBUG - pop widget QPushButton sendButton
2025-02-03 13:53:22,946 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e027140>
2025-02-03 13:53:22,946 - DEBUG - pop layout QHBoxLayout inputLayout
2025-02-03 13:53:22,946 - DEBUG - pop layout QVBoxLayout rightLayout
2025-02-03 13:53:22,946 - DEBUG - pop widget QWidget rightPanel
2025-02-03 13:53:22,946 - DEBUG - new topwidget <PyQt5.QtWidgets.QSplitter object at 0x10e026d50>
2025-02-03 13:53:22,946 - DEBUG - pop widget QSplitter splitter
2025-02-03 13:53:22,946 - DEBUG - new topwidget <PyQt5.QtWidgets.QWidget object at 0x10e026330>
2025-02-03 13:53:22,946 - DEBUG - pop layout QVBoxLayout verticalLayout
2025-02-03 13:53:22,946 - DEBUG - pop widget QWidget centralwidget
2025-02-03 13:53:22,946 - DEBUG - new topwidget <__main__.MainWindow object at 0x10e026cc0>
2025-02-03 13:53:22,946 - DEBUG - pop widget MainWindow MainWindow
2025-02-03 13:53:22,946 - DEBUG - new topwidget None
2025-02-03 13:53:22,947 - DEBUG - Loading configuration from config.yaml
2025-02-03 13:53:22,947 - DEBUG - Initializing RAG
2025-02-03 13:53:22,953 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-03 13:53:23,052 - DEBUG - Starting component System
2025-02-03 13:53:23,052 - DEBUG - Starting component Posthog
2025-02-03 13:53:23,052 - DEBUG - Starting component OpenTelemetryClient
2025-02-03 13:53:23,052 - DEBUG - Starting component SqliteDB
2025-02-03 13:53:23,053 - DEBUG - Starting component SimpleQuotaEnforcer
2025-02-03 13:53:23,053 - DEBUG - Starting component SimpleRateLimitEnforcer
2025-02-03 13:53:23,053 - DEBUG - Starting component LocalSegmentManager
2025-02-03 13:53:23,053 - DEBUG - Starting component LocalExecutor
2025-02-03 13:53:23,053 - DEBUG - Starting component SegmentAPI
2025-02-03 13:53:23,055 - DEBUG - Collection doc already exists, returning existing collection.
2025-02-03 13:53:23,134 - INFO - Loading all indices.
2025-02-03 13:53:23,134 - DEBUG - > [SimpleDirectoryReader] Total files added: 1
2025-02-03 13:53:23,340 - DEBUG - open file: /Users/wingatesv/gen_ai/documents/Marketing and Sales - X.pdf
2025-02-03 13:53:23,340 - WARNING - incorrect startxref pointer(1)
2025-02-03 13:53:23,362 - WARNING - parsing for Object Streams
2025-02-03 13:53:23,406 - WARNING - found 0 objects within Object(381,0) whereas 500 expected
2025-02-03 13:53:23,412 - WARNING - found 0 objects within Object(922,0) whereas 500 expected
2025-02-03 13:53:23,416 - WARNING - found 0 objects within Object(1428,0) whereas 500 expected
2025-02-03 13:53:23,422 - WARNING - found 0 objects within Object(1933,0) whereas 500 expected
2025-02-03 13:53:23,427 - WARNING - found 0 objects within Object(2443,0) whereas 500 expected
2025-02-03 13:53:23,432 - WARNING - found 0 objects within Object(2946,0) whereas 500 expected
2025-02-03 13:53:23,437 - WARNING - found 0 objects within Object(3456,0) whereas 500 expected
2025-02-03 13:53:23,442 - WARNING - found 0 objects within Object(3970,0) whereas 500 expected
2025-02-03 13:53:23,454 - WARNING - found 0 objects within Object(4476,0) whereas 337 expected
2025-02-03 13:53:23,565 - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,852 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,853 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,854 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,855 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,856 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,857 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,858 - DEBUG - > Adding chunk: 
2025-02-03 13:53:23,860 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:24,683 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-03 13:53:25,490 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-03 13:53:38,242 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:39,613 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:40,814 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:42,066 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:43,304 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:44,535 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:45,817 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:47,049 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:48,392 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:53:49,617 - DEBUG - Starting component PersistentLocalHnswSegment
2025-02-03 13:53:49,709 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/docstore.json
2025-02-03 13:53:49,712 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/index_store.json
2025-02-03 13:53:49,713 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/graph_store.json
2025-02-03 13:53:49,713 - DEBUG - open file: /Users/wingatesv/gen_ai/chroma_db/image__vector_store.json
2025-02-03 13:53:49,714 - DEBUG - Setting up internal folder: documents
2025-02-03 13:53:49,714 - DEBUG - Updating document list
2025-02-03 13:53:50,499 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-03 13:54:06,542 - DEBUG - Sending query: what is your main function
2025-02-03 13:54:06,543 - DEBUG - Adding message from user
2025-02-03 13:54:06,548 - DEBUG - Showing dot animation
2025-02-03 13:54:06,548 - DEBUG - Adding message from model
2025-02-03 13:54:06,552 - DEBUG - Using selector: KqueueSelector
2025-02-03 13:54:07,632 - DEBUG - > Top 2 nodes:
2025-02-03 13:54:07,632 - DEBUG - > [Node 1b93a6eb-befa-4bcf-a503-4772374be5f5] [Similarity score: 0.45984991654242846] 74 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
Knowledge Assessment – VI 
Write answers to Long Question...
2025-02-03 13:54:07,632 - DEBUG - > [Node 799e21b5-8bd3-4124-aa98-bab93d0f5719] [Similarity score: 0.45984991654242846] 74 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
Knowledge Assessment – VI 
Write answers to Long Question...
2025-02-03 13:54:07,632 - DEBUG - > Top 2 nodes:
> [Node 1b93a6eb-befa-4bcf-a503-4772374be5f5] [Similarity score:             0.45985] 74 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
Knowledge Assessment – VI 
Write answers to Long Question...
> [Node 799e21b5-8bd3-4124-aa98-bab93d0f5719] [Similarity score:             0.45985] 74 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
Knowledge Assessment – VI 
Write answers to Long Question...
2025-02-03 13:54:07,641 - DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
2025-02-03 13:54:07,988 - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-02-03 13:54:09,938 - DEBUG - https://api-inference.huggingface.co:443 "POST /models/google/gemma-2-2b-it HTTP/1.1" 200 None
2025-02-03 13:54:09,942 - DEBUG - Handling response: 
My main function is to provide information and answer questions based on the provided context. 
I can help you understand the content of the document by summarizing it, answering specific questions, and explaining key concepts. 
My purpose is to assist you in your understanding of the document and its content. 

2025-02-03 13:54:09,942 - DEBUG - Removing dot animation
2025-02-03 13:54:09,942 - DEBUG - Adding message from model
2025-02-03 13:57:27,465 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-03 13:57:27,652 - INFO - Loading existing index...
2025-02-03 13:57:27,652 - INFO - Loading all indices.
2025-02-03 13:57:27,652 - WARNING - Index not found in storage, creating a new one...
2025-02-03 13:57:27,848 - WARNING - incorrect startxref pointer(1)
2025-02-03 13:57:27,870 - WARNING - parsing for Object Streams
2025-02-03 13:57:27,914 - WARNING - found 0 objects within Object(381,0) whereas 500 expected
2025-02-03 13:57:27,920 - WARNING - found 0 objects within Object(922,0) whereas 500 expected
2025-02-03 13:57:27,925 - WARNING - found 0 objects within Object(1428,0) whereas 500 expected
2025-02-03 13:57:27,930 - WARNING - found 0 objects within Object(1933,0) whereas 500 expected
2025-02-03 13:57:27,936 - WARNING - found 0 objects within Object(2443,0) whereas 500 expected
2025-02-03 13:57:27,941 - WARNING - found 0 objects within Object(2946,0) whereas 500 expected
2025-02-03 13:57:27,947 - WARNING - found 0 objects within Object(3456,0) whereas 500 expected
2025-02-03 13:57:27,952 - WARNING - found 0 objects within Object(3970,0) whereas 500 expected
2025-02-03 13:57:27,965 - WARNING - found 0 objects within Object(4476,0) whereas 337 expected
2025-02-03 13:57:28,363 - INFO - Adding 97 new document(s) to the database...
2025-02-03 13:57:40,386 - INFO - Index updated with new documents.
2025-02-03 14:03:56,514 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-03 14:03:56,624 - INFO - Loading existing ChromaDB collection
2025-02-03 14:04:58,062 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-03 14:04:58,164 - INFO - Loading existing ChromaDB collection
2025-02-03 14:11:43,016 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-03 14:11:43,216 - INFO - Loading existing index...
2025-02-03 14:11:43,216 - INFO - Loading all indices.
2025-02-03 14:11:43,216 - WARNING - Index not found in storage, creating a new one...
2025-02-03 14:11:43,470 - WARNING - incorrect startxref pointer(1)
2025-02-03 14:11:43,492 - WARNING - parsing for Object Streams
2025-02-03 14:11:43,536 - WARNING - found 0 objects within Object(381,0) whereas 500 expected
2025-02-03 14:11:43,542 - WARNING - found 0 objects within Object(922,0) whereas 500 expected
2025-02-03 14:11:43,547 - WARNING - found 0 objects within Object(1428,0) whereas 500 expected
2025-02-03 14:11:43,552 - WARNING - found 0 objects within Object(1933,0) whereas 500 expected
2025-02-03 14:11:43,558 - WARNING - found 0 objects within Object(2443,0) whereas 500 expected
2025-02-03 14:11:43,563 - WARNING - found 0 objects within Object(2946,0) whereas 500 expected
2025-02-03 14:11:43,569 - WARNING - found 0 objects within Object(3456,0) whereas 500 expected
2025-02-03 14:11:43,574 - WARNING - found 0 objects within Object(3970,0) whereas 500 expected
2025-02-03 14:11:43,586 - WARNING - found 0 objects within Object(4476,0) whereas 337 expected
2025-02-03 14:11:44,007 - INFO - Adding 97 new document(s) to the database...
2025-02-03 14:12:27,209 - INFO - Index updated with new documents.
2025-02-04 11:45:41,922 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 11:45:42,125 - INFO - Loading existing index...
2025-02-04 11:45:42,125 - INFO - Loading all indices.
2025-02-04 11:45:42,126 - WARNING - Index not found in storage, creating a new one...
2025-02-04 11:45:42,395 - WARNING - incorrect startxref pointer(1)
2025-02-04 11:45:42,418 - WARNING - parsing for Object Streams
2025-02-04 11:45:42,462 - WARNING - found 0 objects within Object(381,0) whereas 500 expected
2025-02-04 11:45:42,468 - WARNING - found 0 objects within Object(922,0) whereas 500 expected
2025-02-04 11:45:42,473 - WARNING - found 0 objects within Object(1428,0) whereas 500 expected
2025-02-04 11:45:42,478 - WARNING - found 0 objects within Object(1933,0) whereas 500 expected
2025-02-04 11:45:42,483 - WARNING - found 0 objects within Object(2443,0) whereas 500 expected
2025-02-04 11:45:42,489 - WARNING - found 0 objects within Object(2946,0) whereas 500 expected
2025-02-04 11:45:42,494 - WARNING - found 0 objects within Object(3456,0) whereas 500 expected
2025-02-04 11:45:42,500 - WARNING - found 0 objects within Object(3970,0) whereas 500 expected
2025-02-04 11:45:42,512 - WARNING - found 0 objects within Object(4476,0) whereas 337 expected
2025-02-04 11:45:42,935 - INFO - Adding 97 new document(s) to the database...
2025-02-04 11:46:40,069 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 11:46:40,263 - INFO - Loading existing index...
2025-02-04 11:46:40,263 - INFO - Loading all indices.
2025-02-04 11:46:40,263 - WARNING - Index not found in storage, creating a new one...
2025-02-04 11:46:40,518 - WARNING - incorrect startxref pointer(1)
2025-02-04 11:46:40,541 - WARNING - parsing for Object Streams
2025-02-04 11:46:40,585 - WARNING - found 0 objects within Object(381,0) whereas 500 expected
2025-02-04 11:46:40,591 - WARNING - found 0 objects within Object(922,0) whereas 500 expected
2025-02-04 11:46:40,596 - WARNING - found 0 objects within Object(1428,0) whereas 500 expected
2025-02-04 11:46:40,601 - WARNING - found 0 objects within Object(1933,0) whereas 500 expected
2025-02-04 11:46:40,607 - WARNING - found 0 objects within Object(2443,0) whereas 500 expected
2025-02-04 11:46:40,612 - WARNING - found 0 objects within Object(2946,0) whereas 500 expected
2025-02-04 11:46:40,617 - WARNING - found 0 objects within Object(3456,0) whereas 500 expected
2025-02-04 11:46:40,623 - WARNING - found 0 objects within Object(3970,0) whereas 500 expected
2025-02-04 11:46:40,635 - WARNING - found 0 objects within Object(4476,0) whereas 337 expected
2025-02-04 11:46:41,049 - INFO - Adding 97 new document(s) to the database...
2025-02-04 11:47:19,975 - INFO - Index updated with new documents.
2025-02-04 11:49:27,462 - INFO - Deleted file: Marketing and Sales - X.pdf
2025-02-04 11:49:42,784 - INFO - Uploaded new files: ['Marketing and Sales - X (1).pdf']
2025-02-04 11:49:46,792 - INFO - Loading existing index...
2025-02-04 11:49:46,792 - INFO - Loading all indices.
2025-02-04 11:49:46,792 - WARNING - Index not found in storage, creating a new one...
2025-02-04 11:49:47,843 - INFO - Adding 97 new document(s) to the database...
2025-02-04 11:50:14,183 - INFO - Index updated with new documents.
2025-02-04 11:50:37,597 - INFO - Uploaded new files: ['FM-LKC FES-FMC-PP-003 Early Submission of Dissertation_Thesis (2).docx']
2025-02-04 11:50:41,058 - INFO - Loading existing index...
2025-02-04 11:50:41,058 - INFO - Loading all indices.
2025-02-04 11:50:41,058 - WARNING - Index not found in storage, creating a new one...
2025-02-04 11:54:03,581 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 11:54:03,780 - INFO - Loading existing index...
2025-02-04 11:54:03,780 - INFO - Loading all indices.
2025-02-04 11:54:03,780 - WARNING - Index not found in storage, creating a new one...
2025-02-04 11:54:05,103 - INFO - Adding 98 new document(s) to the database...
2025-02-04 11:54:21,545 - INFO - Index updated with new documents.
2025-02-04 11:57:29,153 - INFO - Uploaded new files: ['instruction.txt']
2025-02-04 11:57:34,407 - INFO - Loading existing index...
2025-02-04 11:57:34,408 - INFO - Loading all indices.
2025-02-04 11:57:34,408 - WARNING - Index not found in storage, creating a new one...
2025-02-04 11:57:35,488 - INFO - Adding 99 new document(s) to the database...
2025-02-04 11:57:50,779 - INFO - Index updated with new documents.
2025-02-04 12:01:50,540 - ERROR - exception calling callback for <Future at 0x127f95750 state=finished raised ReadTimeout>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/http/client.py", line 1428, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/http/client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/ssl.py", line 1304, in recv_into
    return self.read(nbytes, buffer)
           ~~~~~~~~~^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/ssl.py", line 1138, in read
    return self._sslobj.read(len, buffer)
           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
TimeoutError: [Errno 60] Operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api-inference.huggingface.co', port=443): Read timed out. (read timeout=None)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/_base.py", line 340, in _invoke_callbacks
    callback(self)
    ~~~~~~~~^^^^^^
  File "/Users/wingatesv/gen_ai/main.py", line 234, in <lambda>
    future.add_done_callback(lambda f: self.response_ready.emit(f.result()))
                                                                ~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/wingatesv/gen_ai/main.py", line 230, in query_llm
    return str(hugging_face_query(user_input))
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/Users/wingatesv/gen_ai/llm_query.py", line 92, in hugging_face_query
    response = query_engine.query(prompt)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/base/base_query_engine.py", line 52, in query
    query_result = self._query(str_or_query_bundle)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/query_engine/retriever_query_engine.py", line 179, in _query
    response = self._response_synthesizer.synthesize(
        query=query_bundle,
        nodes=nodes,
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/response_synthesizers/base.py", line 241, in synthesize
    response_str = self.get_response(
        query_str=query.query_str,
    ...<3 lines>...
        **response_kwargs,
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py", line 43, in get_response
    return super().get_response(
           ~~~~~~~~~~~~~~~~~~~~^
        query_str=query_str,
        ^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        **response_kwargs,
        ^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/response_synthesizers/refine.py", line 179, in get_response
    response = self._give_response_single(
        query_str, text_chunk, **response_kwargs
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/response_synthesizers/refine.py", line 241, in _give_response_single
    program(
    ~~~~~~~^
        context_str=cur_text_chunk,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **response_kwargs,
        ^^^^^^^^^^^^^^^^^^
    ),
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/response_synthesizers/refine.py", line 85, in __call__
    answer = self._llm.predict(
        self._prompt,
        **kwds,
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/llms/llm.py", line 600, in predict
    response = self.complete(formatted_prompt, formatted=True)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/llms/huggingface_api/base.py", line 224, in complete
    text=self._sync_client.text_generation(
        prompt, **{**{"max_new_tokens": self.num_output}, **kwargs}
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_client.py", line 2315, in text_generation
    bytes_output = self.post(json=payload, model=model, task="text-generation", stream=stream)  # type: ignore
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_client.py", line 291, in post
    response = get_session().post(
        url,
    ...<6 lines>...
        proxies=self.proxies,
    )
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: (ReadTimeoutError("HTTPSConnectionPool(host='api-inference.huggingface.co', port=443): Read timed out. (read timeout=None)"), '(Request ID: c8d10998-44c1-473f-827f-5769ef28e654)')
2025-02-04 12:21:05,368 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 12:21:05,570 - INFO - Loading existing index...
2025-02-04 12:21:05,570 - INFO - Loading all indices.
2025-02-04 12:21:05,570 - WARNING - Index not found in storage, creating a new one...
2025-02-04 12:21:06,917 - INFO - Adding 99 new document(s) to the database...
2025-02-04 12:21:41,763 - INFO - Index updated with new documents.
2025-02-04 12:23:32,875 - INFO - Deleted file: Marketing and Sales - X (1).pdf
2025-02-04 12:23:52,429 - INFO - Uploaded new files: ['AFX_ML Engineer.pdf']
2025-02-04 12:23:53,760 - INFO - Loading existing index...
2025-02-04 12:23:53,761 - INFO - Loading all indices.
2025-02-04 12:23:53,761 - WARNING - Index not found in storage, creating a new one...
2025-02-04 12:23:53,882 - INFO - Adding 3 new document(s) to the database...
2025-02-04 12:24:18,357 - INFO - Index updated with new documents.
2025-02-04 12:24:18,358 - INFO - RAG update completed
2025-02-04 12:25:56,364 - INFO - Deleted file: AFX_ML Engineer.pdf
2025-02-04 12:27:48,580 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 12:27:48,771 - INFO - Loading existing index...
2025-02-04 12:27:48,771 - INFO - Loading all indices.
2025-02-04 12:27:48,771 - WARNING - Index not found in storage, creating a new one...
2025-02-04 12:27:48,997 - INFO - Adding 2 new document(s) to the database...
2025-02-04 12:27:50,395 - INFO - Index updated with new documents.
2025-02-04 12:27:57,233 - INFO - Deleted file: FM-LKC FES-FMC-PP-003 Early Submission of Dissertation_Thesis (2).docx
2025-02-04 12:27:58,800 - INFO - Loading existing index...
2025-02-04 12:27:58,800 - INFO - Loading all indices.
2025-02-04 12:27:58,800 - WARNING - Index not found in storage, creating a new one...
2025-02-04 12:27:58,847 - INFO - Adding 1 new document(s) to the database...
2025-02-04 12:28:00,037 - INFO - Index updated with new documents.
2025-02-04 12:28:00,038 - INFO - RAG update completed
2025-02-04 12:28:36,921 - INFO - Uploaded new files: ['AFX_ML Engineer.pdf']
2025-02-04 12:28:38,234 - INFO - Loading existing index...
2025-02-04 12:28:38,235 - INFO - Loading all indices.
2025-02-04 12:28:38,235 - WARNING - Index not found in storage, creating a new one...
2025-02-04 12:28:38,343 - INFO - Adding 2 new document(s) to the database...
2025-02-04 12:28:39,464 - INFO - Index updated with new documents.
2025-02-04 12:28:39,464 - INFO - RAG update completed
2025-02-04 14:01:36,203 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 14:01:36,406 - INFO - Loading existing index...
2025-02-04 14:01:36,406 - INFO - Loading all indices.
2025-02-04 14:01:36,406 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:01:36,794 - INFO - Adding 2 new document(s) to the database...
2025-02-04 14:01:38,649 - INFO - Index updated with new documents.
2025-02-04 14:01:52,410 - INFO - Uploaded new files: ['AI Research Scientist (3).pdf']
2025-02-04 14:01:53,971 - INFO - Loading existing index...
2025-02-04 14:01:53,972 - INFO - Loading all indices.
2025-02-04 14:01:53,972 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:01:54,123 - INFO - Adding 3 new document(s) to the database...
2025-02-04 14:01:55,423 - INFO - Index updated with new documents.
2025-02-04 14:01:55,423 - INFO - RAG update completed
2025-02-04 14:06:13,601 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 14:06:13,797 - INFO - Loading existing index...
2025-02-04 14:06:13,797 - INFO - Loading all indices.
2025-02-04 14:06:13,797 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:06:14,120 - INFO - Adding 3 new document(s) to the database...
2025-02-04 14:06:15,854 - INFO - Index updated with new documents.
2025-02-04 14:06:23,271 - INFO - Uploaded new files: ['S0031320324010677.txt']
2025-02-04 14:06:26,159 - INFO - Loading existing index...
2025-02-04 14:06:26,159 - INFO - Loading all indices.
2025-02-04 14:06:26,159 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:06:26,242 - INFO - Adding 4 new document(s) to the database...
2025-02-04 14:06:27,520 - INFO - Index updated with new documents.
2025-02-04 14:06:27,520 - INFO - RAG update completed
2025-02-04 14:06:37,425 - INFO - Deleted file: AI Research Scientist (3).pdf
2025-02-04 14:06:38,458 - INFO - Loading existing index...
2025-02-04 14:06:38,458 - INFO - Loading all indices.
2025-02-04 14:06:38,458 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:06:38,529 - INFO - Adding 3 new document(s) to the database...
2025-02-04 14:06:39,662 - INFO - Index updated with new documents.
2025-02-04 14:06:39,663 - INFO - RAG update completed
2025-02-04 14:07:25,400 - INFO - Uploaded new files: ['Reference Check Form - Phillip Capital (1).pdf', 'openai-chatgpt-latest.vsix']
2025-02-04 14:07:29,060 - INFO - Loading existing index...
2025-02-04 14:07:29,060 - INFO - Loading all indices.
2025-02-04 14:07:29,060 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:07:29,174 - INFO - Adding 7 new document(s) to the database...
2025-02-04 14:07:36,901 - INFO - Index updated with new documents.
2025-02-04 14:07:36,902 - INFO - RAG update completed
2025-02-04 14:07:43,219 - INFO - Uploaded new files: ['dec_2024_statement.pdf', 'RSS EXT Letter ( 1+1+1)- Wingates Voon.pdf']
2025-02-04 14:07:47,195 - INFO - Loading existing index...
2025-02-04 14:07:47,195 - INFO - Loading all indices.
2025-02-04 14:07:47,195 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:07:47,361 - INFO - Adding 11 new document(s) to the database...
2025-02-04 14:07:53,426 - INFO - Index updated with new documents.
2025-02-04 14:07:53,426 - INFO - RAG update completed
2025-02-04 14:07:58,160 - INFO - Deleted file: dec_2024_statement.pdf
2025-02-04 14:07:59,693 - INFO - Loading existing index...
2025-02-04 14:07:59,694 - INFO - Loading all indices.
2025-02-04 14:07:59,694 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:07:59,894 - INFO - Adding 9 new document(s) to the database...
2025-02-04 14:08:06,844 - INFO - Index updated with new documents.
2025-02-04 14:08:06,844 - INFO - RAG update completed
2025-02-04 14:25:09,633 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 14:25:09,827 - INFO - Loading existing index...
2025-02-04 14:25:09,827 - INFO - Loading all indices.
2025-02-04 14:25:09,827 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:25:10,170 - INFO - Adding 9 new document(s) to the database...
2025-02-04 14:25:16,184 - INFO - Index updated with new documents.
2025-02-04 14:30:20,993 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-04 14:30:21,197 - INFO - Loading existing index...
2025-02-04 14:30:21,197 - INFO - Loading all indices.
2025-02-04 14:30:21,197 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:30:21,678 - INFO - Adding 9 new document(s) to the database...
2025-02-04 14:30:27,635 - INFO - Index updated with new documents.
2025-02-04 14:31:28,364 - INFO - Backing off send_request(...) for 0.8s (requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))
2025-02-04 14:31:41,737 - INFO - Deleted file: Reference Check Form - Phillip Capital (1).pdf
2025-02-04 14:31:43,379 - INFO - Loading existing index...
2025-02-04 14:31:43,379 - INFO - Loading all indices.
2025-02-04 14:31:43,379 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:31:43,552 - INFO - Adding 6 new document(s) to the database...
2025-02-04 14:31:48,191 - ERROR - RAG update failed: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:31:54,582 - INFO - Deleted file: S0031320324010677.txt
2025-02-04 14:31:55,952 - INFO - Loading existing index...
2025-02-04 14:31:55,952 - INFO - Loading all indices.
2025-02-04 14:31:55,952 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:31:55,961 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-373' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1459', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'n3snop', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:31:55,967 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-374' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1428', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '-YtOrd', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:31:55,968 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-375' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '949', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'uphwgU', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:31:55,968 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-376' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1179', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'NjgBFd', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:31:55,969 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-378' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1259', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'gXQLaG', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:31:55,970 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-380' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1766', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'zmNm4E', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:31:56,060 - INFO - Adding 5 new document(s) to the database...
2025-02-04 14:31:57,211 - ERROR - RAG update failed: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:03,961 - INFO - Deleted file: RSS EXT Letter ( 1+1+1)- Wingates Voon.pdf
2025-02-04 14:32:05,079 - INFO - Loading existing index...
2025-02-04 14:32:05,080 - INFO - Loading all indices.
2025-02-04 14:32:05,080 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:32:05,150 - INFO - Adding 3 new document(s) to the database...
2025-02-04 14:32:05,176 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-419' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2058', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'mHTnjC', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,177 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-420' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1957', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'ZoQxDv', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,177 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-421' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2242', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'WDY0YK', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,178 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-422' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2297', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '8rPyAz', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,179 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-423' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2181', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '-rJcYv', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,179 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-424' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2246', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'NvtALw', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,179 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-425' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2347', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'rb2egn', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,180 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-426' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1340', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'TCfO6i', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:05,180 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-427' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1410', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '_gD6Ee', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:06,295 - ERROR - RAG update failed: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:12,259 - INFO - Deleted file: instruction.txt
2025-02-04 14:32:14,199 - INFO - Loading existing index...
2025-02-04 14:32:14,200 - INFO - Loading all indices.
2025-02-04 14:32:14,200 - WARNING - Index not found in storage, creating a new one...
2025-02-04 14:32:14,268 - INFO - Adding 2 new document(s) to the database...
2025-02-04 14:32:15,601 - ERROR - RAG update failed: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:32:24,797 - ERROR - exception calling callback for <Future at 0x12d69eb50 state=finished raised ClientResponseError>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/_base.py", line 340, in _invoke_callbacks
    callback(self)
    ~~~~~~~~^^^^^^
  File "/Users/wingatesv/gen_ai/main.py", line 294, in <lambda>
    future.add_done_callback(lambda f: self.response_ready.emit(f.result()))
                                                                ~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/wingatesv/gen_ai/main.py", line 290, in query_llm
    return str(hugging_face_query(user_input))
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/Users/wingatesv/gen_ai/llm_query.py", line 92, in hugging_face_query
    response = query_engine.query(prompt)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/base/base_query_engine.py", line 52, in query
    query_result = self._query(str_or_query_bundle)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/query_engine/retriever_query_engine.py", line 178, in _query
    nodes = self.retrieve(query_bundle)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/query_engine/retriever_query_engine.py", line 133, in retrieve
    nodes = self._retriever.retrieve(query_bundle)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/base/base_retriever.py", line 245, in retrieve
    nodes = self._retrieve(query_bundle)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py", line 99, in _retrieve
    self._embed_model.get_agg_embedding_from_queries(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        query_bundle.embedding_strs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/base/embeddings/base.py", line 187, in get_agg_embedding_from_queries
    query_embeddings = [self.get_query_embedding(query) for query in queries]
                        ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/base/embeddings/base.py", line 136, in get_query_embedding
    query_embedding = self._get_query_embedding(query)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 321, in wrapper
    result = func(*args, **kwargs)
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 175, in _get_query_embedding
    return asyncio.run(self._aget_query_embedding(query))
           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/asyncio/base_events.py", line 720, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/core/instrumentation/dispatcher.py", line 367, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 202, in _aget_query_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_query(query, self.model_name, self.query_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,871 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-470' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2242', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'od68an', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,873 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-471' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2297', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'Ev0IUP', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,874 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-472' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2181', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '6KWqtN', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,875 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-473' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2246', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'd-nDJR', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,875 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-474' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2347', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '0-hCkx', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,876 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-475' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1340', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'x1Zlal', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,876 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-476' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1410', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '983N5e', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,877 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-477' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1406', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '6wnOEP', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,878 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-478' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1192', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'nNQevu', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,879 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-521' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1340', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'gOxP4F', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,880 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-522' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1410', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '2wsYkp', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,880 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-523' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1406', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'iS1nmY', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,881 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-524' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1192', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '619SVq', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,881 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-525' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1480', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'uj6bP3', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,882 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-526' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1263', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'PmB-v1', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,883 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-527' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '407', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'IqaiIe', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,883 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-528' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1051', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'JB9nck', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-04 14:55:39,884 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-529' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1009', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Tue, 04 Feb 2025 06:32:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'df-h2D', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 11:28:47,037 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 11:28:47,238 - INFO - Loading existing index...
2025-02-05 11:28:47,238 - INFO - Loading all indices.
2025-02-05 11:28:47,238 - WARNING - Index not found in storage, creating a new one...
2025-02-05 11:28:47,635 - INFO - Adding 2 new document(s) to the database...
2025-02-05 11:28:53,868 - INFO - Index updated with new documents.
2025-02-05 11:47:50,753 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 11:47:50,945 - INFO - Loading existing index...
2025-02-05 11:47:50,945 - INFO - Loading all indices.
2025-02-05 11:47:50,945 - WARNING - Index not found in storage, creating a new one...
2025-02-05 11:47:51,219 - INFO - Adding 2 new document(s) to the database...
2025-02-05 11:47:56,095 - INFO - Index updated with new documents.
2025-02-05 11:50:23,572 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 11:50:23,760 - INFO - Loading existing index...
2025-02-05 11:50:23,760 - INFO - Loading all indices.
2025-02-05 11:50:23,760 - WARNING - Index not found in storage, creating a new one...
2025-02-05 11:50:24,024 - INFO - Adding 2 new document(s) to the database...
2025-02-05 11:50:29,139 - INFO - Index updated with new documents.
2025-02-05 11:50:45,166 - INFO - Chat session saved as chat_20250205_115045.txt
2025-02-05 11:50:45,167 - ERROR - Error saving chat session: 'MainWindow' object has no attribute 'chatHistoryPanel'
2025-02-05 11:51:50,165 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 11:51:50,370 - INFO - Loading existing index...
2025-02-05 11:51:50,371 - INFO - Loading all indices.
2025-02-05 11:51:50,371 - WARNING - Index not found in storage, creating a new one...
2025-02-05 11:51:50,780 - INFO - Adding 2 new document(s) to the database...
2025-02-05 11:51:57,443 - INFO - Index updated with new documents.
2025-02-05 11:53:49,967 - INFO - Chat session saved as chat_20250205_115349.txt
2025-02-05 11:54:03,980 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 11:54:04,170 - INFO - Loading existing index...
2025-02-05 11:54:04,171 - INFO - Loading all indices.
2025-02-05 11:54:04,171 - WARNING - Index not found in storage, creating a new one...
2025-02-05 11:54:04,459 - INFO - Adding 2 new document(s) to the database...
2025-02-05 11:54:09,110 - INFO - Index updated with new documents.
2025-02-05 11:54:32,674 - INFO - Uploaded new files: ['LLM_test.docx']
2025-02-05 12:11:54,654 - INFO - Chat session saved as chat_20250205_121154.txt
2025-02-05 12:11:58,342 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:11:58,534 - INFO - Loading existing index...
2025-02-05 12:11:58,534 - INFO - Loading all indices.
2025-02-05 12:11:58,534 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:11:58,817 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:12:20,024 - INFO - Index updated with new documents.
2025-02-05 12:12:26,155 - ERROR - Error loading chat session chat_20250205_115045.txt: Expecting value: line 1 column 1 (char 0)
2025-02-05 12:12:36,993 - INFO - Chat session saved as chat_20250205_121236.json
2025-02-05 12:12:36,994 - ERROR - Error saving chat session: 'MainWindow' object has no attribute 'chatHistoryPanel'
2025-02-05 12:13:47,668 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:13:47,854 - INFO - Loading existing index...
2025-02-05 12:13:47,855 - INFO - Loading all indices.
2025-02-05 12:13:47,855 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:13:48,117 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:13:52,979 - INFO - Index updated with new documents.
2025-02-05 12:14:04,948 - INFO - Chat session saved as chat_20250205_121404.json
2025-02-05 12:17:16,957 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:17:17,159 - INFO - Loading existing index...
2025-02-05 12:17:17,160 - INFO - Loading all indices.
2025-02-05 12:17:17,160 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:17:17,590 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:17:22,518 - INFO - Index updated with new documents.
2025-02-05 12:17:32,478 - INFO - Chat session saved as chat_20250205_121732.json
2025-02-05 12:17:40,030 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:17:40,208 - INFO - Loading existing index...
2025-02-05 12:17:40,208 - INFO - Loading all indices.
2025-02-05 12:17:40,208 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:17:40,474 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:17:45,392 - INFO - Index updated with new documents.
2025-02-05 12:22:31,218 - INFO - Chat session saved as chat_20250205_122231.json
2025-02-05 12:26:56,538 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:26:56,739 - INFO - Loading existing index...
2025-02-05 12:26:56,739 - INFO - Loading all indices.
2025-02-05 12:26:56,739 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:26:57,162 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:27:04,126 - INFO - Index updated with new documents.
2025-02-05 12:27:08,655 - INFO - Chat session saved as chat_20250205_122708.json
2025-02-05 12:27:45,618 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:27:45,808 - INFO - Loading existing index...
2025-02-05 12:27:45,808 - INFO - Loading all indices.
2025-02-05 12:27:45,808 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:27:46,125 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:27:50,899 - INFO - Index updated with new documents.
2025-02-05 12:28:03,047 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_122231.json
2025-02-05 12:28:17,436 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:28:17,623 - INFO - Loading existing index...
2025-02-05 12:28:17,623 - INFO - Loading all indices.
2025-02-05 12:28:17,623 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:28:17,887 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:28:23,629 - INFO - Index updated with new documents.
2025-02-05 12:28:33,868 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_121732.json
2025-02-05 12:28:47,585 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:28:47,765 - INFO - Loading existing index...
2025-02-05 12:28:47,765 - INFO - Loading all indices.
2025-02-05 12:28:47,765 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:28:47,987 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:28:53,025 - INFO - Index updated with new documents.
2025-02-05 12:29:10,340 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_122708.json
2025-02-05 12:33:43,900 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:33:44,102 - INFO - Loading existing index...
2025-02-05 12:33:44,102 - INFO - Loading all indices.
2025-02-05 12:33:44,102 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:33:44,543 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:33:49,520 - INFO - Index updated with new documents.
2025-02-05 12:36:44,667 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_123644.json
2025-02-05 12:36:48,323 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:36:48,511 - INFO - Loading existing index...
2025-02-05 12:36:48,511 - INFO - Loading all indices.
2025-02-05 12:36:48,511 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:36:48,793 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:36:53,623 - INFO - Index updated with new documents.
2025-02-05 12:37:03,239 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_121732.json
2025-02-05 12:41:45,722 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:41:45,917 - INFO - Loading existing index...
2025-02-05 12:41:45,917 - INFO - Loading all indices.
2025-02-05 12:41:45,917 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:41:46,280 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:41:51,387 - INFO - Index updated with new documents.
2025-02-05 12:41:54,843 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-05 12:41:54,844 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_121732.json
2025-02-05 12:42:07,556 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_122708.json
2025-02-05 12:42:14,308 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:42:14,485 - INFO - Loading existing index...
2025-02-05 12:42:14,485 - INFO - Loading all indices.
2025-02-05 12:42:14,485 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:42:14,699 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:42:19,247 - INFO - Index updated with new documents.
2025-02-05 12:42:54,513 - INFO - Chat space is empty. No new session created.
2025-02-05 12:42:56,125 - INFO - Chat space is empty. No new session created.
2025-02-05 12:42:57,744 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-05 12:42:57,746 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_122708.json
2025-02-05 12:43:00,030 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-05 12:43:00,031 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_121732.json
2025-02-05 12:44:38,435 - INFO - Uploaded new files: ['AFX_ML Engineer.pdf']
2025-02-05 12:44:49,161 - INFO - Uploaded new files: ['Marketing and Sales - X.pdf']
2025-02-05 12:51:28,649 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_121732.json
2025-02-05 12:51:32,445 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:51:32,634 - INFO - Loading existing index...
2025-02-05 12:51:32,634 - INFO - Loading all indices.
2025-02-05 12:51:32,634 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:51:33,893 - INFO - Adding 100 new document(s) to the database...
2025-02-05 12:53:20,829 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:53:21,031 - INFO - Loading existing index...
2025-02-05 12:53:21,031 - INFO - Loading all indices.
2025-02-05 12:53:21,031 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:53:21,460 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:53:26,150 - INFO - Index updated with new documents.
2025-02-05 12:53:36,446 - ERROR - Error loading chat session chat_20250205_122708 : [Errno 2] No such file or directory: '/Users/wingatesv/gen_ai/chat_histories/chat_20250205_122708 '
2025-02-05 12:53:43,068 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_125343.json
2025-02-05 12:54:40,176 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:54:40,375 - INFO - Loading existing index...
2025-02-05 12:54:40,375 - INFO - Loading all indices.
2025-02-05 12:54:40,375 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:54:40,832 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:54:45,726 - INFO - Index updated with new documents.
2025-02-05 12:54:47,435 - ERROR - Error loading chat session chat_20250205_122708 .json: [Errno 2] No such file or directory: '/Users/wingatesv/gen_ai/chat_histories/chat_20250205_122708 .json'
2025-02-05 12:54:51,678 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_125451.json
2025-02-05 12:55:00,334 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:55:00,549 - INFO - Loading existing index...
2025-02-05 12:55:00,549 - INFO - Loading all indices.
2025-02-05 12:55:00,549 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:55:00,842 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:55:05,686 - INFO - Index updated with new documents.
2025-02-05 12:56:41,391 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_123644.json
2025-02-05 12:56:44,992 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:56:45,182 - INFO - Loading existing index...
2025-02-05 12:56:45,182 - INFO - Loading all indices.
2025-02-05 12:56:45,182 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:56:45,475 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:56:50,323 - INFO - Index updated with new documents.
2025-02-05 12:56:53,643 - INFO - Chat session is empty, nothing to save.
2025-02-05 12:57:11,395 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:57:11,574 - INFO - Loading existing index...
2025-02-05 12:57:11,574 - INFO - Loading all indices.
2025-02-05 12:57:11,574 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:57:11,824 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:57:16,675 - INFO - Index updated with new documents.
2025-02-05 12:57:24,503 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_125724.json
2025-02-05 12:57:31,547 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:57:31,725 - INFO - Loading existing index...
2025-02-05 12:57:31,725 - INFO - Loading all indices.
2025-02-05 12:57:31,725 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:57:31,982 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:57:37,123 - INFO - Index updated with new documents.
2025-02-05 12:57:42,392 - INFO - Chat session is empty, nothing to save.
2025-02-05 12:59:30,279 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:59:30,482 - INFO - Loading existing index...
2025-02-05 12:59:30,482 - INFO - Loading all indices.
2025-02-05 12:59:30,482 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:59:30,957 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:59:34,874 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-111' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '867', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'NRg34X', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:34,875 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-109' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1265', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '3KkaM1', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:34,875 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-108' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1526', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'oiz11C', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:34,876 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-105' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1412', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'KGOIcJ', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:41,448 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 12:59:41,626 - INFO - Loading existing index...
2025-02-05 12:59:41,626 - INFO - Loading all indices.
2025-02-05 12:59:41,626 - WARNING - Index not found in storage, creating a new one...
2025-02-05 12:59:41,842 - INFO - Adding 3 new document(s) to the database...
2025-02-05 12:59:43,322 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'GrokzA', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,323 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '0an-gb', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,323 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'KeJMao', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,324 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'SIPApo', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,324 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '7_uMln', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,324 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'z9klOU', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,325 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'zrnUdm', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,325 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'URWbYi', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 12:59:43,326 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 04:59:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '1seWNk', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:23,148 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 13:43:23,354 - INFO - Loading existing index...
2025-02-05 13:43:23,354 - INFO - Loading all indices.
2025-02-05 13:43:23,354 - WARNING - Index not found in storage, creating a new one...
2025-02-05 13:43:23,859 - INFO - Adding 3 new document(s) to the database...
2025-02-05 13:43:26,170 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': '9r8Ois', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,170 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': '4fT_ra', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,171 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': '036VWN', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,171 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': '5lKvnA', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,172 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'K-A8Jb', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,172 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'ZCWfcK', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,173 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'CZ3U2v', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,173 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'CSDzNl', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 13:43:26,173 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 05:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'DGFw4S', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:55,384 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 17:31:55,591 - INFO - Loading existing index...
2025-02-05 17:31:55,591 - INFO - Loading all indices.
2025-02-05 17:31:55,591 - WARNING - Index not found in storage, creating a new one...
2025-02-05 17:31:56,122 - INFO - Adding 3 new document(s) to the database...
2025-02-05 17:31:58,078 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'EhnSZ7', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,079 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'TApsJQ', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,079 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': '4PbAxA', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,080 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'q3MjgO', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,080 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'WxDTNP', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,081 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'nGn1xs', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,081 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'vE0JTK', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,081 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'mURS-j', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:31:58,082 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer ', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=401, message='Unauthorized', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:31:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '28', 'Connection': 'keep-alive', 'x-request-id': 'plpKtG', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 401, message='Unauthorized', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:08,120 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 17:32:08,300 - INFO - Loading existing index...
2025-02-05 17:32:08,300 - INFO - Loading all indices.
2025-02-05 17:32:08,300 - WARNING - Index not found in storage, creating a new one...
2025-02-05 17:32:08,698 - INFO - Adding 3 new document(s) to the database...
2025-02-05 17:32:10,467 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'mLt-xu', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,468 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'OW1XGk', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,468 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'GgEbUU', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,469 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'MwfkeE', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,469 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'vGzAWx', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,469 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'hvMShQ', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,470 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'mLD4RE', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,470 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'zyeMMI', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:32:10,471 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:32:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'O_OOh7', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:32,232 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 17:33:32,437 - INFO - Loading existing index...
2025-02-05 17:33:32,437 - INFO - Loading all indices.
2025-02-05 17:33:32,437 - WARNING - Index not found in storage, creating a new one...
2025-02-05 17:33:32,912 - INFO - Adding 3 new document(s) to the database...
2025-02-05 17:33:34,303 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'lnZj9O', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,304 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'sEmgZm', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,305 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'EuBL-g', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,305 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'nlNplK', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,305 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'Zy3-lR', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,306 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'FTYtI8', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,306 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'TygCEe', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,307 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'Kt29yV', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:34,307 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'rt1wYP', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:52,638 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-05 17:33:52,813 - INFO - Loading existing index...
2025-02-05 17:33:52,813 - INFO - Loading all indices.
2025-02-05 17:33:52,813 - WARNING - Index not found in storage, creating a new one...
2025-02-05 17:33:53,029 - INFO - Adding 3 new document(s) to the database...
2025-02-05 17:33:54,487 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'kpEY6c', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,488 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'yzsLDH', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,489 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'Vorwc0', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,489 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'XoaqlL', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,489 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '2-PBet', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,490 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': '_OT0dx', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,490 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'l4rt9D', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,491 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'aVDLId', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-05 17:33:54,491 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Wed, 05 Feb 2025 09:33:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'T43PHH', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
2025-02-06 11:17:48,811 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 11:17:49,013 - INFO - Loading existing index...
2025-02-06 11:17:49,013 - INFO - Loading all indices.
2025-02-06 11:17:49,013 - WARNING - Index not found in storage, creating a new one...
2025-02-06 11:17:49,544 - INFO - Adding 3 new document(s) to the database...
2025-02-06 11:17:56,370 - INFO - Index updated with new documents.
2025-02-06 11:34:46,052 - INFO - Uploaded new files: ['nov_2024_statement.pdf', 'oct_2024_statement.pdf']
2025-02-06 12:24:27,243 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_122427.json
2025-02-06 12:24:43,056 - ERROR - Error loading stylesheet: [Errno 2] No such file or directory: 'resources/light_mode.qss'
2025-02-06 12:24:43,095 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 12:24:43,299 - INFO - Loading existing index...
2025-02-06 12:24:43,299 - INFO - Loading all indices.
2025-02-06 12:24:43,299 - WARNING - Index not found in storage, creating a new one...
2025-02-06 12:24:43,844 - INFO - Adding 8 new document(s) to the database...
2025-02-06 12:25:14,017 - INFO - Index updated with new documents.
2025-02-06 12:25:16,745 - INFO - Chat session is empty, nothing to save.
2025-02-06 12:25:30,711 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 12:25:30,904 - INFO - Loading existing index...
2025-02-06 12:25:30,905 - INFO - Loading all indices.
2025-02-06 12:25:30,905 - WARNING - Index not found in storage, creating a new one...
2025-02-06 12:25:31,334 - INFO - Adding 3 new document(s) to the database...
2025-02-06 12:25:36,262 - INFO - Index updated with new documents.
2025-02-06 12:25:54,481 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_125724.json
2025-02-06 12:29:15,625 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 12:29:15,824 - INFO - Loading existing index...
2025-02-06 12:29:15,824 - INFO - Loading all indices.
2025-02-06 12:29:15,824 - WARNING - Index not found in storage, creating a new one...
2025-02-06 12:29:16,318 - INFO - Adding 3 new document(s) to the database...
2025-02-06 12:29:23,695 - INFO - Index updated with new documents.
2025-02-06 12:29:39,078 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_122939.json
2025-02-06 12:30:07,763 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 12:30:07,963 - INFO - Loading existing index...
2025-02-06 12:30:07,963 - INFO - Loading all indices.
2025-02-06 12:30:07,963 - WARNING - Index not found in storage, creating a new one...
2025-02-06 12:30:08,459 - INFO - Adding 3 new document(s) to the database...
2025-02-06 12:30:13,568 - INFO - Index updated with new documents.
2025-02-06 12:37:30,171 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250205_125724.json
2025-02-06 12:37:35,047 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 12:37:35,239 - INFO - Loading existing index...
2025-02-06 12:37:35,240 - INFO - Loading all indices.
2025-02-06 12:37:35,240 - WARNING - Index not found in storage, creating a new one...
2025-02-06 12:37:35,546 - INFO - Adding 3 new document(s) to the database...
2025-02-06 12:37:40,441 - INFO - Index updated with new documents.
2025-02-06 12:38:07,204 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-06 12:38:07,206 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_123807.json
2025-02-06 12:38:14,348 - ERROR - Error loading chat session chat_20250206_123807.json.json: [Errno 2] No such file or directory: '/Users/wingatesv/gen_ai/chat_histories/chat_20250206_123807.json.json'
2025-02-06 12:38:17,690 - INFO - Chat session is empty, nothing to save.
2025-02-06 12:41:39,004 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 12:41:39,210 - INFO - Loading existing index...
2025-02-06 12:41:39,211 - INFO - Loading all indices.
2025-02-06 12:41:39,211 - WARNING - Index not found in storage, creating a new one...
2025-02-06 12:41:39,717 - INFO - Adding 3 new document(s) to the database...
2025-02-06 12:41:44,483 - INFO - Index updated with new documents.
2025-02-06 12:41:50,002 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-06 12:41:50,004 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_124150.json
2025-02-06 12:41:59,127 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_124150.json
2025-02-06 13:26:20,987 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 13:26:21,187 - INFO - Loading existing index...
2025-02-06 13:26:21,187 - INFO - Loading all indices.
2025-02-06 13:26:21,187 - WARNING - Index not found in storage, creating a new one...
2025-02-06 13:26:21,678 - INFO - Adding 3 new document(s) to the database...
2025-02-06 13:26:45,054 - INFO - Index updated with new documents.
2025-02-06 13:48:45,951 - INFO - Chat session is empty, nothing to save.
2025-02-06 13:48:49,675 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 13:48:49,866 - INFO - Loading existing index...
2025-02-06 13:48:49,866 - INFO - Loading all indices.
2025-02-06 13:48:49,866 - WARNING - Index not found in storage, creating a new one...
2025-02-06 13:48:50,163 - INFO - Adding 3 new document(s) to the database...
2025-02-06 13:48:54,990 - INFO - Index updated with new documents.
2025-02-06 13:49:29,069 - INFO - Chat session is empty, nothing to save.
2025-02-06 13:49:40,920 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 13:49:41,112 - INFO - Loading existing index...
2025-02-06 13:49:41,112 - INFO - Loading all indices.
2025-02-06 13:49:41,112 - WARNING - Index not found in storage, creating a new one...
2025-02-06 13:49:41,469 - INFO - Adding 3 new document(s) to the database...
2025-02-06 13:49:46,110 - INFO - Index updated with new documents.
2025-02-06 13:58:49,749 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_135849.json
2025-02-06 13:58:53,317 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 13:58:53,526 - INFO - Loading existing index...
2025-02-06 13:58:53,526 - INFO - Loading all indices.
2025-02-06 13:58:53,526 - WARNING - Index not found in storage, creating a new one...
2025-02-06 13:58:53,849 - INFO - Adding 3 new document(s) to the database...
2025-02-06 13:59:04,521 - INFO - Index updated with new documents.
2025-02-06 14:05:16,585 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_140516.json
2025-02-06 14:05:20,892 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 14:05:21,086 - INFO - Loading existing index...
2025-02-06 14:05:21,086 - INFO - Loading all indices.
2025-02-06 14:05:21,086 - WARNING - Index not found in storage, creating a new one...
2025-02-06 14:05:21,399 - INFO - Adding 3 new document(s) to the database...
2025-02-06 14:05:26,410 - INFO - Index updated with new documents.
2025-02-06 16:57:46,483 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_165746.json
2025-02-06 16:57:50,358 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 16:57:50,559 - INFO - Loading existing index...
2025-02-06 16:57:50,559 - INFO - Loading all indices.
2025-02-06 16:57:50,559 - WARNING - Index not found in storage, creating a new one...
2025-02-06 16:57:50,912 - INFO - Adding 3 new document(s) to the database...
2025-02-06 16:58:15,575 - INFO - Index updated with new documents.
2025-02-06 16:59:36,599 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_140516.json
2025-02-06 16:59:47,680 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-06 16:59:47,868 - INFO - Loading existing index...
2025-02-06 16:59:47,868 - INFO - Loading all indices.
2025-02-06 16:59:47,868 - WARNING - Index not found in storage, creating a new one...
2025-02-06 16:59:48,158 - INFO - Adding 3 new document(s) to the database...
2025-02-06 17:00:10,592 - INFO - Index updated with new documents.
2025-02-06 17:13:43,253 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_140516.json
2025-02-10 11:09:43,213 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:09:43,432 - INFO - Loading existing index...
2025-02-10 11:09:43,433 - INFO - Loading all indices.
2025-02-10 11:09:43,433 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:09:44,222 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:11:41,935 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:11:42,112 - INFO - Loading existing index...
2025-02-10 11:11:42,113 - INFO - Loading all indices.
2025-02-10 11:11:42,113 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:11:42,342 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:12:01,664 - INFO - Index updated with new documents.
2025-02-10 11:12:26,994 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-10 11:12:26,996 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_165746.json
2025-02-10 11:26:48,486 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 11:26:52,353 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:26:52,545 - INFO - Loading existing index...
2025-02-10 11:26:52,545 - INFO - Loading all indices.
2025-02-10 11:26:52,545 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:26:52,972 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:26:57,917 - INFO - Index updated with new documents.
2025-02-10 11:27:31,444 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 11:30:15,237 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:30:15,413 - INFO - Loading existing index...
2025-02-10 11:30:15,413 - INFO - Loading all indices.
2025-02-10 11:30:15,413 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:30:15,641 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:30:17,253 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientConnectorDNSError(ConnectionKey(host='api-inference.huggingface.co', port=443, is_ssl=True, ssl=True, proxy=None, proxy_auth=None, proxy_headers_hash=None), gaierror(8, 'nodename nor servname provided, or not known'))>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/connector.py", line 1351, in _create_direct_connection
    hosts = await self._resolve_host(host, port, traces=traces)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/connector.py", line 995, in _resolve_host
    return await asyncio.shield(resolved_host_task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/connector.py", line 1026, in _resolve_host_with_throttle
    addrs = await self._resolver.resolve(host, port, family=self._family)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/resolver.py", line 36, in resolve
    infos = await self._loop.getaddrinfo(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<5 lines>...
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/asyncio/base_events.py", line 934, in getaddrinfo
    return await self.run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        None, getaddr_func, host, port, family, type, proto, flags)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/concurrent/futures/thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/socket.py", line 975, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 8] nodename nor servname provided, or not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 294, in post
    response = await session.post(url, json=json, data=data_as_binary, proxy=self.proxies)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 3067, in _request
    response = await session._wrapped_request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client.py", line 703, in _request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        req, traces=traces, timeout=real_timeout
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/connector.py", line 548, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/connector.py", line 1056, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/connector.py", line 1357, in _create_direct_connection
    raise ClientConnectorDNSError(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorDNSError: Cannot connect to host api-inference.huggingface.co:443 ssl:default [nodename nor servname provided, or not known]
2025-02-10 11:30:51,087 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:30:51,261 - INFO - Loading existing index...
2025-02-10 11:30:51,261 - INFO - Loading all indices.
2025-02-10 11:30:51,261 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:30:51,490 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:30:56,088 - INFO - Index updated with new documents.
2025-02-10 11:56:47,571 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 11:56:51,309 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:56:51,501 - INFO - Loading existing index...
2025-02-10 11:56:51,501 - INFO - Loading all indices.
2025-02-10 11:56:51,501 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:56:51,992 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:56:57,055 - INFO - Index updated with new documents.
2025-02-10 11:58:16,201 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_140516.json
2025-02-10 11:58:38,947 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:58:39,136 - INFO - Loading existing index...
2025-02-10 11:58:39,136 - INFO - Loading all indices.
2025-02-10 11:58:39,136 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:58:39,589 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:58:44,400 - INFO - Index updated with new documents.
2025-02-10 11:58:49,519 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_165746.json
2025-02-10 11:58:57,839 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 11:58:58,014 - INFO - Loading existing index...
2025-02-10 11:58:58,014 - INFO - Loading all indices.
2025-02-10 11:58:58,014 - WARNING - Index not found in storage, creating a new one...
2025-02-10 11:58:58,250 - INFO - Adding 3 new document(s) to the database...
2025-02-10 11:59:03,774 - INFO - Index updated with new documents.
2025-02-10 12:01:03,933 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_140516.json
2025-02-10 12:01:26,468 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:01:26,657 - INFO - Loading existing index...
2025-02-10 12:01:26,657 - INFO - Loading all indices.
2025-02-10 12:01:26,657 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:01:27,129 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:01:32,405 - INFO - Index updated with new documents.
2025-02-10 12:02:26,183 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_120226.json
2025-02-10 12:02:39,773 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:02:39,957 - INFO - Loading existing index...
2025-02-10 12:02:39,957 - INFO - Loading all indices.
2025-02-10 12:02:39,957 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:02:40,203 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:02:45,295 - INFO - Index updated with new documents.
2025-02-10 12:03:17,215 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250206_140516.json
2025-02-10 12:03:25,111 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:03:25,290 - INFO - Loading existing index...
2025-02-10 12:03:25,290 - INFO - Loading all indices.
2025-02-10 12:03:25,290 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:03:25,528 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:03:30,985 - INFO - Index updated with new documents.
2025-02-10 12:11:32,934 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 12:11:36,514 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:11:36,704 - INFO - Loading existing index...
2025-02-10 12:11:36,704 - INFO - Loading all indices.
2025-02-10 12:11:36,704 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:11:37,121 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:11:41,885 - INFO - Index updated with new documents.
2025-02-10 12:19:30,331 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 12:19:33,912 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:19:34,103 - INFO - Loading existing index...
2025-02-10 12:19:34,103 - INFO - Loading all indices.
2025-02-10 12:19:34,103 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:19:34,519 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:19:39,234 - INFO - Index updated with new documents.
2025-02-10 12:20:24,582 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 12:20:28,505 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:20:28,694 - INFO - Loading existing index...
2025-02-10 12:20:28,694 - INFO - Loading all indices.
2025-02-10 12:20:28,694 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:20:29,044 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:20:33,700 - INFO - Index updated with new documents.
2025-02-10 12:21:17,626 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 12:21:25,701 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:21:25,889 - INFO - Loading existing index...
2025-02-10 12:21:25,889 - INFO - Loading all indices.
2025-02-10 12:21:25,889 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:21:26,245 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:21:30,868 - INFO - Index updated with new documents.
2025-02-10 12:21:57,314 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 12:28:03,240 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:28:03,441 - INFO - Loading existing index...
2025-02-10 12:28:03,441 - INFO - Loading all indices.
2025-02-10 12:28:03,441 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:28:04,010 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:28:09,145 - INFO - Index updated with new documents.
2025-02-10 12:38:15,449 - INFO - Chat session is empty, nothing to save.
2025-02-10 12:39:57,508 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:39:57,699 - INFO - Loading existing index...
2025-02-10 12:39:57,700 - INFO - Loading all indices.
2025-02-10 12:39:57,700 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:39:58,193 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:40:03,955 - INFO - Index updated with new documents.
2025-02-10 12:40:51,830 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 12:40:54,585 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:40:54,775 - INFO - Loading existing index...
2025-02-10 12:40:54,775 - INFO - Loading all indices.
2025-02-10 12:40:54,775 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:40:55,131 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:40:59,782 - INFO - Index updated with new documents.
2025-02-10 12:51:48,103 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250210_112648.json
2025-02-10 12:51:51,439 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-10 12:51:51,629 - INFO - Loading existing index...
2025-02-10 12:51:51,629 - INFO - Loading all indices.
2025-02-10 12:51:51,629 - WARNING - Index not found in storage, creating a new one...
2025-02-10 12:51:52,077 - INFO - Adding 3 new document(s) to the database...
2025-02-10 12:51:57,166 - INFO - Index updated with new documents.
2025-02-10 12:52:15,056 - INFO - Chat session is empty, nothing to save.
2025-02-11 10:42:48,329 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 10:42:48,549 - INFO - Loading existing index...
2025-02-11 10:42:48,549 - INFO - Loading all indices.
2025-02-11 10:42:48,549 - WARNING - Index not found in storage, creating a new one...
2025-02-11 10:42:49,389 - INFO - Adding 3 new document(s) to the database...
2025-02-11 10:43:09,933 - INFO - Index updated with new documents.
2025-02-11 10:46:15,538 - INFO - Chat session is empty, nothing to save.
2025-02-11 10:46:19,484 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 10:46:19,660 - INFO - Loading existing index...
2025-02-11 10:46:19,660 - INFO - Loading all indices.
2025-02-11 10:46:19,660 - WARNING - Index not found in storage, creating a new one...
2025-02-11 10:46:19,905 - INFO - Adding 3 new document(s) to the database...
2025-02-11 10:46:24,549 - INFO - Index updated with new documents.
2025-02-11 10:47:12,635 - INFO - Settings saved and applied.
2025-02-11 10:58:08,830 - INFO - Chat session is empty, nothing to save.
2025-02-11 10:58:12,042 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 10:58:12,216 - INFO - Loading existing index...
2025-02-11 10:58:12,216 - INFO - Loading all indices.
2025-02-11 10:58:12,216 - WARNING - Index not found in storage, creating a new one...
2025-02-11 10:58:12,461 - INFO - Adding 3 new document(s) to the database...
2025-02-11 10:58:14,083 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'sHQeUr', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,084 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'Dz8tMx', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,085 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'hE3G3c', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,085 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'MBHetJ', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,086 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'eDDUjr', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,086 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': '7uM1Tw', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,087 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'HR9pGt', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,087 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'iSOspN', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:14,087 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'YLOYV9', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:19,781 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 10:58:19,958 - INFO - Loading existing index...
2025-02-11 10:58:19,958 - INFO - Loading all indices.
2025-02-11 10:58:19,958 - WARNING - Index not found in storage, creating a new one...
2025-02-11 10:58:20,203 - INFO - Adding 3 new document(s) to the database...
2025-02-11 10:58:21,611 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2113', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'zMb5eP', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,612 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-9' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2917', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'woc9H2', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,612 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2652', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'P3G2Lb', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,613 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3276', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'GiXo4C', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,613 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3356', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'u8W4Zl', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,613 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2427', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': '0HX5c9', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,614 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '3119', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'Lk5k2h', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,614 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '1894', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': 'fwpjdg', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:58:21,615 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '2172', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding')), (), status=404, message='Not Found', headers=<CIMultiDictProxy('Date': 'Tue, 11 Feb 2025 02:58:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '38', 'Connection': 'keep-alive', 'x-request-id': '02H04v', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 404, message='Not Found', url='https://api-inference.huggingface.co/pipeline/feature-extraction/OpenAI%20Embedding'
2025-02-11 10:59:07,014 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 10:59:07,189 - INFO - Loading existing index...
2025-02-11 10:59:07,189 - INFO - Loading all indices.
2025-02-11 10:59:07,189 - WARNING - Index not found in storage, creating a new one...
2025-02-11 10:59:07,433 - INFO - Adding 3 new document(s) to the database...
2025-02-11 10:59:12,625 - INFO - Index updated with new documents.
2025-02-11 11:00:06,352 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:09:41,563 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:09:41,759 - INFO - Loading existing index...
2025-02-11 15:09:41,759 - INFO - Loading all indices.
2025-02-11 15:09:41,759 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:09:42,368 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:09:52,423 - INFO - Index updated with new documents.
2025-02-11 15:19:13,845 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:19:30,927 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:19:31,116 - INFO - Loading existing index...
2025-02-11 15:19:31,116 - INFO - Loading all indices.
2025-02-11 15:19:31,116 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:19:31,682 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:19:38,944 - INFO - Index updated with new documents.
2025-02-11 15:22:01,415 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:22:01,602 - INFO - Loading existing index...
2025-02-11 15:22:01,602 - INFO - Loading all indices.
2025-02-11 15:22:01,603 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:22:02,106 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:22:11,748 - INFO - Index updated with new documents.
2025-02-11 15:23:18,461 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:23:18,639 - INFO - Loading existing index...
2025-02-11 15:23:18,639 - INFO - Loading all indices.
2025-02-11 15:23:18,639 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:23:19,092 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:23:25,249 - INFO - Index updated with new documents.
2025-02-11 15:23:51,469 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:27:38,025 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:27:38,201 - INFO - Loading existing index...
2025-02-11 15:27:38,202 - INFO - Loading all indices.
2025-02-11 15:27:38,202 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:27:38,723 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:27:44,167 - INFO - Index updated with new documents.
2025-02-11 15:28:49,535 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:28:49,718 - INFO - Loading existing index...
2025-02-11 15:28:49,718 - INFO - Loading all indices.
2025-02-11 15:28:49,718 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:28:50,236 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:28:56,353 - INFO - Index updated with new documents.
2025-02-11 15:29:00,863 - INFO - Settings saved and applied.
2025-02-11 15:29:18,221 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:29:22,787 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:29:22,964 - INFO - Loading existing index...
2025-02-11 15:29:22,964 - INFO - Loading all indices.
2025-02-11 15:29:22,964 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:29:23,449 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:29:29,141 - INFO - Index updated with new documents.
2025-02-11 15:29:38,910 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:30:13,887 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:30:14,067 - INFO - Loading existing index...
2025-02-11 15:30:14,068 - INFO - Loading all indices.
2025-02-11 15:30:14,068 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:30:14,548 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:30:20,710 - INFO - Index updated with new documents.
2025-02-11 15:30:27,832 - INFO - Settings saved and applied.
2025-02-11 15:30:30,336 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:30:33,371 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:30:33,552 - INFO - Loading existing index...
2025-02-11 15:30:33,552 - INFO - Loading all indices.
2025-02-11 15:30:33,552 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:30:34,071 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:30:40,331 - INFO - Index updated with new documents.
2025-02-11 15:31:08,567 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:38:22,390 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:38:22,587 - INFO - Loading existing index...
2025-02-11 15:38:22,587 - INFO - Loading all indices.
2025-02-11 15:38:22,587 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:38:23,185 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:38:29,741 - INFO - Index updated with new documents.
2025-02-11 15:40:00,558 - INFO - Settings saved and applied.
2025-02-11 15:40:04,360 - INFO - Chat session is empty, nothing to save.
2025-02-11 15:43:50,077 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:43:50,253 - INFO - Loading existing index...
2025-02-11 15:43:50,253 - INFO - Loading all indices.
2025-02-11 15:43:50,253 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:43:50,515 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:43:56,834 - INFO - Index updated with new documents.
2025-02-11 15:45:13,588 - INFO - Settings saved and applied.
2025-02-11 15:45:25,614 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250211_154525.json
2025-02-11 15:48:14,641 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:48:14,816 - INFO - Loading existing index...
2025-02-11 15:48:14,816 - INFO - Loading all indices.
2025-02-11 15:48:14,816 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:48:15,139 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:48:23,914 - INFO - Index updated with new documents.
2025-02-11 15:48:50,302 - INFO - Settings saved and applied.
2025-02-11 15:48:54,640 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250211_154854.json
2025-02-11 15:53:07,959 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-11 15:53:08,135 - INFO - Loading existing index...
2025-02-11 15:53:08,135 - INFO - Loading all indices.
2025-02-11 15:53:08,135 - WARNING - Index not found in storage, creating a new one...
2025-02-11 15:53:08,561 - INFO - Adding 3 new document(s) to the database...
2025-02-11 15:53:17,415 - INFO - Index updated with new documents.
2025-02-11 15:55:34,854 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250211_154854.json
2025-02-12 10:40:49,774 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 10:40:50,011 - INFO - Loading existing index...
2025-02-12 10:40:50,011 - INFO - Loading all indices.
2025-02-12 10:40:50,011 - WARNING - Index not found in storage, creating a new one...
2025-02-12 10:40:51,036 - INFO - Adding 3 new document(s) to the database...
2025-02-12 10:41:11,630 - INFO - Index updated with new documents.
2025-02-12 10:43:55,456 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 10:43:55,458 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 10:43:59,494 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 10:43:59,496 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 10:44:05,380 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 10:44:05,381 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:31:02,890 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:31:06,952 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 11:31:07,144 - INFO - Loading existing index...
2025-02-12 11:31:07,144 - INFO - Loading all indices.
2025-02-12 11:31:07,144 - WARNING - Index not found in storage, creating a new one...
2025-02-12 11:31:07,730 - INFO - Adding 3 new document(s) to the database...
2025-02-12 11:31:13,792 - INFO - Index updated with new documents.
2025-02-12 11:37:45,523 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 11:37:45,525 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:37:55,064 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 11:37:55,065 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:37:58,527 - INFO - Chat session is empty, nothing to save.
2025-02-12 11:39:05,334 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 11:39:05,520 - INFO - Loading existing index...
2025-02-12 11:39:05,520 - INFO - Loading all indices.
2025-02-12 11:39:05,520 - WARNING - Index not found in storage, creating a new one...
2025-02-12 11:39:06,063 - INFO - Adding 3 new document(s) to the database...
2025-02-12 11:39:13,449 - INFO - Index updated with new documents.
2025-02-12 11:39:20,544 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 11:39:20,546 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:39:30,255 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 11:39:30,256 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:40:00,900 - INFO - Chat space populated. Saving current session and creating a new chat session.
2025-02-12 11:40:00,901 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:55:35,820 - INFO - Chat session is empty, nothing to save.
2025-02-12 11:55:39,020 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 11:55:39,208 - INFO - Loading existing index...
2025-02-12 11:55:39,208 - INFO - Loading all indices.
2025-02-12 11:55:39,208 - WARNING - Index not found in storage, creating a new one...
2025-02-12 11:55:39,766 - INFO - Adding 3 new document(s) to the database...
2025-02-12 11:55:59,323 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 11:55:59,499 - INFO - Loading existing index...
2025-02-12 11:55:59,499 - INFO - Loading all indices.
2025-02-12 11:55:59,500 - WARNING - Index not found in storage, creating a new one...
2025-02-12 11:55:59,759 - INFO - Adding 3 new document(s) to the database...
2025-02-12 11:56:05,425 - INFO - Index updated with new documents.
2025-02-12 11:57:28,928 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 11:57:29,116 - INFO - Loading existing index...
2025-02-12 11:57:29,116 - INFO - Loading all indices.
2025-02-12 11:57:29,116 - WARNING - Index not found in storage, creating a new one...
2025-02-12 11:57:29,669 - INFO - Adding 3 new document(s) to the database...
2025-02-12 11:57:34,858 - INFO - Index updated with new documents.
2025-02-12 11:57:40,452 - INFO - Chat space populated. Saving current session and continuing chat.
2025-02-12 11:57:40,455 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:57:40,455 - INFO - Continuing chat in session: /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:58:23,823 - INFO - Chat space populated. Saving current session and continuing chat.
2025-02-12 11:58:23,825 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 11:58:23,825 - INFO - Continuing chat in session: /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 12:00:44,877 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 12:00:55,662 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:00:55,835 - INFO - Loading existing index...
2025-02-12 12:00:55,835 - INFO - Loading all indices.
2025-02-12 12:00:55,835 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:00:56,100 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:01:04,038 - INFO - Index updated with new documents.
2025-02-12 12:03:03,148 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 12:03:05,850 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:03:06,026 - INFO - Loading existing index...
2025-02-12 12:03:06,026 - INFO - Loading all indices.
2025-02-12 12:03:06,026 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:03:06,286 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:03:14,176 - INFO - Index updated with new documents.
2025-02-12 12:03:27,632 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_120327.json
2025-02-12 12:08:35,778 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:08:35,977 - INFO - Loading existing index...
2025-02-12 12:08:35,977 - INFO - Loading all indices.
2025-02-12 12:08:35,977 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:08:36,529 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:08:44,410 - INFO - Index updated with new documents.
2025-02-12 12:09:12,453 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 12:09:12,453 - INFO - Starting a new chat session.
2025-02-12 12:09:51,534 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_120951.json
2025-02-12 12:09:56,242 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:09:56,417 - INFO - Loading existing index...
2025-02-12 12:09:56,417 - INFO - Loading all indices.
2025-02-12 12:09:56,417 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:09:56,681 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:10:04,845 - INFO - Index updated with new documents.
2025-02-12 12:15:18,578 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_120951.json
2025-02-12 12:15:24,352 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:15:24,542 - INFO - Loading existing index...
2025-02-12 12:15:24,542 - INFO - Loading all indices.
2025-02-12 12:15:24,542 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:15:25,034 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:15:33,019 - INFO - Index updated with new documents.
2025-02-12 12:16:28,949 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 12:24:48,446 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:24:48,632 - INFO - Loading existing index...
2025-02-12 12:24:48,632 - INFO - Loading all indices.
2025-02-12 12:24:48,632 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:24:49,135 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:24:56,671 - INFO - Index updated with new documents.
2025-02-12 12:25:16,409 - INFO - Chat session is empty, nothing to save.
2025-02-12 12:26:49,831 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:26:50,020 - INFO - Loading existing index...
2025-02-12 12:26:50,020 - INFO - Loading all indices.
2025-02-12 12:26:50,020 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:26:50,301 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:26:58,001 - INFO - Index updated with new documents.
2025-02-12 12:27:11,402 - INFO - Settings saved and applied.
2025-02-12 12:27:18,940 - INFO - Chat session is empty, nothing to save.
2025-02-12 12:27:22,366 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:27:22,545 - INFO - Loading existing index...
2025-02-12 12:27:22,545 - INFO - Loading all indices.
2025-02-12 12:27:22,545 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:27:22,969 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:27:30,691 - INFO - Index updated with new documents.
2025-02-12 12:28:09,345 - INFO - Settings saved and applied.
2025-02-12 12:28:12,561 - INFO - Chat session is empty, nothing to save.
2025-02-12 12:28:16,663 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:28:16,840 - INFO - Loading existing index...
2025-02-12 12:28:16,840 - INFO - Loading all indices.
2025-02-12 12:28:16,840 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:28:17,107 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:28:24,561 - INFO - Index updated with new documents.
2025-02-12 12:29:29,898 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_104355.json
2025-02-12 12:52:06,548 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-12 12:52:06,748 - INFO - Loading existing index...
2025-02-12 12:52:06,748 - INFO - Loading all indices.
2025-02-12 12:52:06,748 - WARNING - Index not found in storage, creating a new one...
2025-02-12 12:52:07,424 - INFO - Adding 3 new document(s) to the database...
2025-02-12 12:52:14,569 - INFO - Index updated with new documents.
2025-02-12 12:52:27,323 - INFO - Chat session is empty, nothing to save.
2025-02-15 15:57:16,537 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-15 15:57:16,758 - INFO - Loading existing index...
2025-02-15 15:57:16,758 - INFO - Loading all indices.
2025-02-15 15:57:16,758 - WARNING - Index not found in storage, creating a new one...
2025-02-15 15:57:17,721 - INFO - Adding 3 new document(s) to the database...
2025-02-15 15:57:40,730 - INFO - Index updated with new documents.
2025-02-15 17:24:37,994 - INFO - Chat session saved as /Users/wingatesv/gen_ai/chat_histories/chat_20250212_120327.json
2025-02-15 17:24:41,294 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-15 17:24:41,493 - INFO - Loading existing index...
2025-02-15 17:24:41,493 - INFO - Loading all indices.
2025-02-15 17:24:41,493 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:24:41,876 - INFO - Adding 3 new document(s) to the database...
2025-02-15 17:24:55,327 - INFO - Index updated with new documents.
2025-02-15 17:27:14,522 - INFO - Chat session is empty, nothing to save.
2025-02-15 17:27:27,464 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-15 17:27:27,638 - INFO - Loading existing index...
2025-02-15 17:27:27,638 - INFO - Loading all indices.
2025-02-15 17:27:27,638 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:27:27,905 - INFO - Adding 3 new document(s) to the database...
2025-02-15 17:27:32,942 - INFO - Index updated with new documents.
2025-02-15 17:27:52,200 - INFO - Chat session is empty, nothing to save.
2025-02-15 17:28:04,957 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-15 17:28:05,134 - INFO - Loading existing index...
2025-02-15 17:28:05,134 - INFO - Loading all indices.
2025-02-15 17:28:05,134 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:28:05,401 - INFO - Adding 3 new document(s) to the database...
2025-02-15 17:28:13,459 - INFO - Index updated with new documents.
2025-02-15 17:28:58,893 - INFO - Chat session is empty, nothing to save.
2025-02-15 17:32:45,953 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-15 17:32:46,130 - INFO - Loading existing index...
2025-02-15 17:32:46,130 - INFO - Loading all indices.
2025-02-15 17:32:46,130 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:32:46,403 - INFO - Adding 3 new document(s) to the database...
2025-02-15 17:32:51,471 - INFO - Index updated with new documents.
2025-02-15 17:36:16,416 - INFO - Uploaded new files: ['Data Science with RapidMiner - Professional.pdf']
2025-02-15 17:36:17,826 - INFO - Loading existing index...
2025-02-15 17:36:17,826 - INFO - Loading all indices.
2025-02-15 17:36:17,826 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:36:19,796 - INFO - Adding 248 new document(s) to the database...
2025-02-15 17:36:30,387 - INFO - Uploaded new files: ['03. ML Pro.pptx']
2025-02-15 17:36:31,687 - INFO - Loading existing index...
2025-02-15 17:36:31,688 - INFO - Loading all indices.
2025-02-15 17:36:31,688 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:36:31,699 - ERROR - RAG update failed: Please install extra dependencies that are required for the PptxReader: `pip install torch transformers python-pptx Pillow`
2025-02-15 17:36:58,626 - INFO - Deleted file: AFX_ML Engineer.pdf
2025-02-15 17:37:03,667 - INFO - Deleted file: LLM_test.docx
2025-02-15 17:37:08,045 - INFO - Deleted file: 03. ML Pro.pptx
2025-02-15 17:37:12,012 - INFO - Deleted file: Data Science with RapidMiner - Professional.pdf
2025-02-15 17:37:36,649 - INFO - Index updated with new documents.
2025-02-15 17:37:36,649 - INFO - RAG update completed
2025-02-15 17:37:42,073 - INFO - Uploaded new files: ['Data Science with RapidMiner - Professional.pdf']
2025-02-15 17:37:43,588 - INFO - Loading existing index...
2025-02-15 17:37:43,589 - INFO - Loading all indices.
2025-02-15 17:37:43,589 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:37:45,524 - INFO - Adding 246 new document(s) to the database...
2025-02-15 17:37:46,610 - INFO - Uploaded new files: ['03. ML Pro.pptx']
2025-02-15 17:37:48,076 - INFO - Loading existing index...
2025-02-15 17:37:48,076 - INFO - Loading all indices.
2025-02-15 17:37:48,076 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:37:48,096 - ERROR - RAG update failed: Please install extra dependencies that are required for the PptxReader: `pip install torch transformers python-pptx Pillow`
2025-02-15 17:38:33,959 - INFO - Index updated with new documents.
2025-02-15 17:38:33,960 - INFO - RAG update completed
2025-02-15 17:52:02,834 - INFO - Chat session is empty, nothing to save.
2025-02-15 17:52:08,060 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-15 17:52:08,250 - INFO - Loading existing index...
2025-02-15 17:52:08,251 - INFO - Loading all indices.
2025-02-15 17:52:08,251 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:52:28,837 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-02-15 17:52:29,010 - INFO - Loading existing index...
2025-02-15 17:52:29,010 - INFO - Loading all indices.
2025-02-15 17:52:29,010 - WARNING - Index not found in storage, creating a new one...
2025-02-15 17:52:31,153 - INFO - Adding 246 new document(s) to the database...
2025-02-15 17:53:18,923 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-1251' coro=<HuggingFaceInferenceAPIEmbedding._aget_text_embedding() done, defined at /Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py:206> exception=ClientResponseError(RequestInfo(url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'), method='POST', headers=<CIMultiDictProxy('Host': 'api-inference.huggingface.co', 'user-agent': 'unknown/None; hf_hub/0.27.1; python/3.13.1', 'authorization': 'Bearer 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', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '478', 'Content-Type': 'application/json')>, real_url=URL('https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5')), (), status=429, message='Too Many Requests', headers=<CIMultiDictProxy('Date': 'Sat, 15 Feb 2025 09:53:18 GMT', 'Content-Type': 'application/json', 'Content-Length': '179', 'Connection': 'keep-alive', 'x-request-id': 'e_E_pK', 'Vary': 'origin, access-control-request-method, access-control-request-headers', 'Access-Control-Allow-Credentials': 'true')>)>
Traceback (most recent call last):
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 207, in _aget_text_embedding
    return await self._async_embed_single(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=format_text(text, self.model_name, self.text_instruction)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/llama_index/embeddings/huggingface_api/base.py", line 146, in _async_embed_single
    embedding = await self._async_client.feature_extraction(text)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 1110, in feature_extraction
    response = await self.post(**payload, model=model, task="feature-extraction")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 334, in post
    raise error
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/huggingface_hub/inference/_generated/_async_client.py", line 301, in post
    response.raise_for_status()
  File "/Users/wingatesv/anaconda3/envs/genai/lib/python3.13/site-packages/aiohttp/client_reqrep.py", line 1161, in raise_for_status
    raise ClientResponseError(
    ...<5 lines>...
    )
aiohttp.client_exceptions.ClientResponseError: 429, message='Too Many Requests', url='https://api-inference.huggingface.co/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
